{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harmonic Oscillator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$m\\frac{d^2u}{dt^2} + \\mu\\frac{du}{dt} + k u =0,\\quad u(0)=1,\\quad \\frac{du}{dt}(0) = 0,\\quad t\\in[0, 1]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        \n",
    "def to_tensor(x):\n",
    "    return torch.tensor(x).float().view(-1, 1).to(device)\n",
    "\n",
    "def to_array(x):\n",
    "    return x.view(-1).cpu().detach().numpy()\n",
    "\n",
    "def gradient(y, x):\n",
    "    return torch.autograd.grad(y, x, grad_outputs=torch.ones_like(y),\n",
    "                               create_graph=True, retain_graph=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Equation parameters:\n",
    "d, w0 = 2, 20       ## reference value w0 = 20\n",
    "mu, k = 2*d, w0**2\n",
    "\n",
    "t_min, t_max, t_size = 0, 1, 101\n",
    "t = np.linspace(t_min, t_max, t_size)       # (t_size,)\n",
    "\n",
    "n_pde = 101\n",
    "## Domain: u_tt + mu * u_t + k * u\n",
    "t_pde = np.random.rand(n_pde)*(t_max - t_min) + t_min\n",
    "t_pde = to_tensor(t_pde)\n",
    "\n",
    "t_ic = to_tensor(0)\n",
    "u_ic = to_tensor(0)\n",
    "du_ic = to_tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 50),  nn.Tanh(),\n",
    "            nn.Linear(50, 50), nn.Tanh(),\n",
    "            nn.Linear(50, 50), nn.Tanh(),\n",
    "            nn.Linear(50, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        return self.net(t)  # (N, 1)\n",
    "    \n",
    "    def residual_loss(self, t, mu=mu, k=k):\n",
    "        t.requires_grad = True\n",
    "        u = self.forward(t)\n",
    "        u_t = gradient(u, t)\n",
    "        u_tt = gradient(u_t, t)\n",
    "        residual = u_tt + mu * u_t + k * u\n",
    "        return torch.mean(residual**2)\n",
    "    \n",
    "    def ic_du_loss(self, t):\n",
    "        t.requires_grad = True\n",
    "        u = self.forward(t)\n",
    "        u_t = gradient(u, t)\n",
    "        return torch.mean((u_t - torch.full_like(t, 0))**2)\n",
    "    \n",
    "    def ic_u_loss(self, t):\n",
    "        u = self.forward(t)\n",
    "        return torch.mean((u - torch.full_like(t, 1))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "n_epochs = 10000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = PINN().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.985)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    model.train()\n",
    "    loss_pde = model.residual_loss(t_pde)\n",
    "    loss_ic_du = model.ic_du_loss(t_ic)\n",
    "    loss_ic_u = model.ic_u_loss(t_ic)\n",
    "\n",
    "    loss = loss_pde + loss_ic_du + loss_ic_u\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if epoch % (n_epochs // 10) == 0:\n",
    "        print(f\"[{epoch:5d}/{n_epochs}] (lr: {scheduler.get_last_lr()[0]:.2e}) \"\n",
    "              f\"loss: {loss.item():.2e} \"\n",
    "              f\"(pde: {loss_pde.item():.2e} ic_du: {loss_ic_du.item():.2e} \"\n",
    "              f\"ic_u: {loss_ic_u.item():.2e})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
