{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, value_and_grad\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "\n",
    "# 모델 정의 (Linen 사용)\n",
    "class PINN(nn.Module):\n",
    "    hidden_size: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, t, x):\n",
    "        input_data = jnp.concatenate([t, x], axis=-1)\n",
    "        x = nn.Dense(self.hidden_size)(input_data)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(self.hidden_size)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(1)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collocation points\n",
    "x = jnp.linspace(0, 1, 100).reshape(-1, 1)\n",
    "t = jnp.linspace(0, 1, 100).reshape(-1, 1)\n",
    "\n",
    "# Boundary conditions\n",
    "x_bc = jnp.array([[0.0], [1.0]])\n",
    "t_bc = jnp.array([[0.0], [0.0]])\n",
    "u_bc = jnp.array([[0.0], [0.0]])\n",
    "\n",
    "# Initial condition\n",
    "n_ic = 100\n",
    "x_ic = jnp.linspace(0, 1, n_ic).reshape(-1, 1)\n",
    "t_ic = jnp.zeros_like(x_ic)\n",
    "u_ic = jnp.sin(jnp.pi * x_ic)\n",
    "\n",
    "data = {}\n",
    "data['bc'] = t_bc, x_bc, u_bc\n",
    "data['ic'] = t_ic, x_ic, u_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "alpha = 1.0\n",
    "hidden_size = 20\n",
    "\n",
    "# 난수 키 생성 및 모델 초기화\n",
    "key = jax.random.PRNGKey(0)\n",
    "model = PINN(hidden_size=hidden_size)\n",
    "optimizer = optax.adam(learning_rate=0.001)\n",
    "\n",
    "params = model.init(key, x, t)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "# 손실 함수\n",
    "def loss_fn(params, t, x, alpha, data):\n",
    "    func   = lambda *args: model.apply(params, *args).sum()     # args = (t, x)\n",
    "    grad_0 = lambda *args: grad(func, argnums=0)(*args).sum()   # args = (t, x)\n",
    "    grad_1 = lambda *args: grad(func, argnums=1)(*args).sum()   # args = (t, x)\n",
    "\n",
    "    u = model.apply(params, t, x)\n",
    "    u_t = grad(func, argnums=0)(t, x)\n",
    "    u_x = grad(func, argnums=1)(t, x)\n",
    "    u_xx = grad(grad_1, argnums=1)(t, x)\n",
    "\n",
    "    residual = u_t - alpha * u_xx\n",
    "    loss = pde_loss = jnp.mean(residual**2)\n",
    "    aux = {\"pde\": pde_loss}\n",
    "\n",
    "    for name in data:\n",
    "        t_data, x_data, u_data = data[name]\n",
    "        u_pred = model.apply(params, t_data, x_data)\n",
    "        aux[name] = jnp.mean((u_pred - u_data)**2)\n",
    "        loss += aux[name]\n",
    "\n",
    "    return loss, aux\n",
    "\n",
    "# 학습 스텝 (JIT 컴파일)\n",
    "@jax.jit\n",
    "def train_step(params, opt_state, t, x, alpha, data={}):\n",
    "    # loss, grads = jax.value_and_grad(loss_fn)(params, t, x, alpha)\n",
    "    (loss, aux), grads = jax.value_and_grad(loss_fn, has_aux=True)(params, t, x, alpha, data)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss, aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1000/10000] Loss: 1.956e-03 bc: 2.252e-04 ic: 1.388e-03 pde: 3.431e-04\n",
      "[ 2000/10000] Loss: 1.608e-04 bc: 7.807e-06 ic: 8.058e-05 pde: 7.241e-05\n",
      "[ 3000/10000] Loss: 3.912e-05 bc: 1.542e-06 ic: 1.837e-05 pde: 1.921e-05\n",
      "[ 4000/10000] Loss: 1.765e-05 bc: 8.272e-07 ic: 8.452e-06 pde: 8.373e-06\n",
      "[ 5000/10000] Loss: 1.009e-05 bc: 4.204e-07 ic: 4.064e-06 pde: 5.608e-06\n",
      "[ 6000/10000] Loss: 2.251e-04 bc: 8.542e-06 ic: 1.721e-05 pde: 1.993e-04\n",
      "[ 7000/10000] Loss: 1.964e-04 bc: 1.682e-05 ic: 1.829e-05 pde: 1.612e-04\n",
      "[ 8000/10000] Loss: 4.596e-06 bc: 8.214e-08 ic: 1.204e-06 pde: 3.309e-06\n",
      "[ 9000/10000] Loss: 4.148e-05 bc: 2.843e-06 ic: 4.990e-06 pde: 3.365e-05\n",
      "[10000/10000] Loss: 3.474e-06 bc: 4.524e-08 ic: 9.580e-07 pde: 2.470e-06\n",
      "CPU times: total: 3.34 s\n",
      "Wall time: 2.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs = 10000   # epoch 수 증가\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    params, opt_state, loss, aux = train_step(params, opt_state, t, x, alpha, data)\n",
    "\n",
    "    desc = f\"[{epoch:5d}/{n_epochs}] Loss: {loss:.3e} \"\n",
    "    desc += \" \".join([f\"{name}: {aux[name]:.3e}\" for name in aux])\n",
    "\n",
    "    if epoch % (n_epochs // 10) == 0:\n",
    "        print(desc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
