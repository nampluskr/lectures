{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel(1, 1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "def loss_fn(y_pred, y):\n",
    "    return torch.mean((y_pred - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20/200] loss: 4.4325 rsme: -1.1053\n",
      "[ 40/200] loss: 1.5287 rsme: -0.2364\n",
      "[ 60/200] loss: 0.8847 rsme: 0.0594\n",
      "[ 80/200] loss: 0.4109 rsme: 0.3590\n",
      "[100/200] loss: 0.1191 rsme: 0.6549\n",
      "[120/200] loss: 0.0630 rsme: 0.7491\n",
      "[140/200] loss: 0.0228 rsme: 0.8489\n",
      "[160/200] loss: 0.0080 rsme: 0.9105\n",
      "[180/200] loss: 0.0059 rsme: 0.9230\n",
      "[200/200] loss: 0.0023 rsme: 0.9526\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    inputs = torch.randn(32, 1)\n",
    "    targets = inputs * 2\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    rsme  = 1 - torch.sqrt(torch.mean((outputs - targets)**2))\n",
    "\n",
    "    if epoch % (n_epochs // 10) == 0:\n",
    "        print(f\"[{epoch:3d}/{n_epochs}] loss: {loss.item():.4f} rsme: {rsme.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flax.linen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nnx.Module):\n",
    "    def __init__(self, input_dim, output_dim, rngs: nnx.Rngs):\n",
    "        self.linear = nnx.Linear(input_dim, output_dim, rngs=rngs)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "rngs = nnx.Rngs(key)\n",
    "\n",
    "model = LinearModel(1, 1, rngs=rngs)\n",
    "optimizer = nnx.Optimizer(model, optax.sgd(learning_rate=0.01))\n",
    "\n",
    "def loss_fn(model, x, y):\n",
    "    y_pred = model(x)\n",
    "    loss = jnp.mean((y_pred - y)**2)\n",
    "    return loss, y_pred\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model, optimizer, x, y):\n",
    "    (loss, outputs), grads = nnx.value_and_grad(loss_fn, has_aux=True)(model, x, y)\n",
    "    optimizer.update(grads)\n",
    "    return loss, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20/200] loss: 0.009 rsme: 0.905\n",
      "[ 40/200] loss: 0.005 rsme: 0.931\n",
      "[ 60/200] loss: 0.003 rsme: 0.950\n",
      "[ 80/200] loss: 0.001 rsme: 0.963\n",
      "[100/200] loss: 0.001 rsme: 0.973\n",
      "[120/200] loss: 0.000 rsme: 0.980\n",
      "[140/200] loss: 0.000 rsme: 0.985\n",
      "[160/200] loss: 0.000 rsme: 0.989\n",
      "[180/200] loss: 0.000 rsme: 0.992\n",
      "[200/200] loss: 0.000 rsme: 0.994\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    inputs = jax.random.normal(key, (32, 1))\n",
    "    targets = inputs * 2\n",
    "    loss, outputs = train_step(model, optimizer, inputs, targets)\n",
    "    rsme = 1 - jnp.sqrt(jnp.mean((outputs - targets)**2))\n",
    "    \n",
    "    if epoch % (n_epochs // 10) == 0:\n",
    "        print(f\"[{epoch:3d}/{n_epochs}] loss: {loss:.3f} rsme: {rsme:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        return nn.Dense(features=1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "model = LinearModel()\n",
    "params = model.init(key, jnp.ones((1, 1)))\n",
    "\n",
    "optimizer = optax.sgd(learning_rate=0.01)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "def loss_fn(params, x, y):\n",
    "    y_pred = model.apply(params, x)\n",
    "    loss = jnp.mean((y_pred - y)**2)\n",
    "    return loss, y_pred\n",
    "\n",
    "@jax.jit\n",
    "def train_step(params, opt_state, x, y):\n",
    "    (loss, outputs), grads = jax.value_and_grad(loss_fn, has_aux=True)(params, x, y)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20/200] loss: 1.896 rsme: -0.377\n",
      "[ 40/200] loss: 0.994 rsme: 0.003\n",
      "[ 60/200] loss: 0.526 rsme: 0.275\n",
      "[ 80/200] loss: 0.281 rsme: 0.470\n",
      "[100/200] loss: 0.151 rsme: 0.611\n",
      "[120/200] loss: 0.082 rsme: 0.714\n",
      "[140/200] loss: 0.045 rsme: 0.789\n",
      "[160/200] loss: 0.024 rsme: 0.844\n",
      "[180/200] loss: 0.013 rsme: 0.885\n",
      "[200/200] loss: 0.007 rsme: 0.915\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    inputs = jax.random.normal(key, (32, 1))\n",
    "    targets = inputs * 2\n",
    "    params, opt_state, loss, outputs = train_step(params, opt_state, inputs, targets)\n",
    "    rsme = 1 - jnp.sqrt(jnp.mean((outputs - targets)**2))\n",
    "    \n",
    "    if epoch % (n_epochs // 10) == 0:\n",
    "        print(f\"[{epoch:3d}/{n_epochs}] loss: {loss:.3f} rsme: {rsme:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
