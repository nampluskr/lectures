{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "\n",
    "# 모델 정의 (Linen 사용)\n",
    "class PINN(nn.Module):\n",
    "    hidden_size: int\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, t, x):\n",
    "        input_data = jnp.concatenate([t, x], axis=-1)\n",
    "        x = nn.Dense(self.hidden_size)(input_data)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(self.hidden_size)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(1)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1000/10000] Loss: 7.516e-03 pde: 2.258e-05 bc: 1.437e-03 ic: 6.057e-03\n",
      "[ 2000/10000] Loss: 2.846e-03 pde: 2.645e-06 bc: 4.630e-04 ic: 2.381e-03\n",
      "[ 3000/10000] Loss: 1.452e-03 pde: 4.011e-05 bc: 1.795e-04 ic: 1.232e-03\n",
      "[ 4000/10000] Loss: 8.993e-04 pde: 1.213e-06 bc: 1.151e-04 ic: 7.830e-04\n",
      "[ 5000/10000] Loss: 6.111e-04 pde: 1.174e-07 bc: 7.181e-05 ic: 5.392e-04\n",
      "[ 6000/10000] Loss: 7.218e-04 pde: 2.150e-04 bc: 7.523e-05 ic: 4.316e-04\n",
      "[ 7000/10000] Loss: 3.919e-04 pde: 4.028e-08 bc: 3.672e-05 ic: 3.552e-04\n",
      "[ 8000/10000] Loss: 3.288e-04 pde: 4.315e-08 bc: 2.923e-05 ic: 2.995e-04\n",
      "[ 9000/10000] Loss: 2.844e-04 pde: 8.141e-08 bc: 2.475e-05 ic: 2.596e-04\n",
      "[10000/10000] Loss: 2.547e-04 pde: 1.248e-08 bc: 2.183e-05 ic: 2.328e-04\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터\n",
    "alpha = 1.0\n",
    "hidden_size = 20\n",
    "\n",
    "# 난수 키 생성 및 모델 초기화\n",
    "key = jax.random.PRNGKey(0)\n",
    "model = PINN(hidden_size=hidden_size)\n",
    "\n",
    "x = jnp.linspace(0, 1, 100).reshape(-1, 1)\n",
    "t = jnp.linspace(0, 1, 100).reshape(-1, 1)\n",
    "params = model.init(key, x, t)\n",
    "\n",
    "# 옵티마이저 초기화\n",
    "optimizer = optax.adam(learning_rate=0.001)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "# 손실 함수\n",
    "@jax.jit\n",
    "def loss_fn(params, t, x, alpha):\n",
    "    # pde = lambda t, x : model(params, t, x)\n",
    "    u_t = jax.grad(lambda *args: model.apply(params, *args).sum())(x, t)[0]\n",
    "    u_x = jax.grad(lambda *args: model.apply(params, *args).sum())(x, t)[1]\n",
    "    u_xx = jax.grad(lambda *args: u_x.sum())(x, t)[1]\n",
    "\n",
    "    # u = model.apply(params, t, x)\n",
    "    # u_t  = jax.grad(lambda t, x: u.sum(), argnums=0)(x, t)\n",
    "    # u_x  = jax.grad(lambda t, x: u.sum(), argnums=1)(x, t)\n",
    "    # u_xx = jax.grad(lambda t, x: u_x.sum(), argnums=1)(x, t)\n",
    "\n",
    "    residual = u_t - alpha * u_xx\n",
    "    pde_loss = jnp.mean(residual**2)\n",
    "\n",
    "    # Boundary conditions\n",
    "    x_bc = jnp.array([[0.0], [1.0]])\n",
    "    t_bc = jnp.array([[0.0], [0.0]])\n",
    "    u_bc = model.apply(params, x_bc, t_bc)\n",
    "    bc_loss = jnp.mean(u_bc**2)\n",
    "\n",
    "    # Initial condition\n",
    "    n_ic = 100\n",
    "    x_ic = jnp.linspace(0, 1, n_ic).reshape(-1, 1)\n",
    "    t_ic = jnp.zeros_like(x_ic)\n",
    "    u_ic = model.apply(params, x_ic, t_ic)\n",
    "    ic_loss = jnp.mean((u_ic - jnp.sin(jnp.pi * x_ic))**2)\n",
    "\n",
    "    loss = pde_loss + bc_loss + ic_loss\n",
    "    return loss, (pde_loss, bc_loss, ic_loss)\n",
    "\n",
    "# 학습 스텝 (JIT 컴파일)\n",
    "@jax.jit\n",
    "def train_step(params, opt_state, t, x, alpha):\n",
    "    # loss, grads = jax.value_and_grad(loss_fn)(params, t, x, alpha)\n",
    "    (loss, aux), grads = jax.value_and_grad(loss_fn, has_aux=True)(params, t, x, alpha)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss, aux\n",
    "\n",
    "# 학습 루프\n",
    "n_epochs = 10000   # epoch 수 증가\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    params, opt_state, loss, aux = train_step(params, opt_state, t, x, alpha)\n",
    "    pde_loss, bc_loss, ic_loss = aux\n",
    "\n",
    "    if epoch % (n_epochs // 10) == 0:\n",
    "        print(f\"[{epoch:5d}/{n_epochs}] Loss: {loss:.3e} \"\n",
    "              f\"pde: {pde_loss:.3e} bc: {bc_loss:.3e} ic: {ic_loss:.3e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
