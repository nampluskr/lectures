{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Train images: (50000, 32, 32, 3), uint8\n",
      ">> Train labels: (50000,), int64\n",
      ">> Test images:  (10000, 32, 32, 3), uint8\n",
      ">> Test labels:  (10000,), int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def unpickle(filename):\n",
    "    # tar -zxvf cifar-10-python.tar.gz\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='bytes')\n",
    "\n",
    "    x = np.array(data[b'data']).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "    y = np.array(data[b'labels'])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def load_cifar10(data_dir):\n",
    "    batch_files = [os.path.join(data_dir, f\"data_batch_{i+1}\") for i in range(5)]\n",
    "    test_file = os.path.join(data_dir, \"test_batch\")\n",
    "\n",
    "    images, labels = [], []\n",
    "    for filename in batch_files:\n",
    "        x, y = unpickle(filename)\n",
    "        images.append(x)\n",
    "        labels.append(y)\n",
    "\n",
    "    x_train = np.concatenate(images, axis=0)\n",
    "    y_train = np.concatenate(labels, axis=0)\n",
    "\n",
    "    x_test, y_test = unpickle(test_file)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "# data_dir = r\"D:\\datasets\\cifar10_178M\\cifar-10-batches-py\"    ## windows\n",
    "data_dir = \"/mnt/d/datasets/cifar10_178M/cifar-10-batches-py\"   ## wsl\n",
    "(x_train, y_train), (x_test, y_test) = load_cifar10(data_dir)\n",
    "\n",
    "print(f\">> Train images: {x_train.shape}, {x_train.dtype}\")\n",
    "print(f\">> Train labels: {y_train.shape}, {y_train.dtype}\")\n",
    "print(f\">> Test images:  {x_test.shape}, {x_test.dtype}\")\n",
    "print(f\">> Test labels:  {y_test.shape}, {y_test.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> x: torch.Size([32, 3, 32, 32]), torch.float32, min=-1.0, max=1.0\n",
      ">> y: torch.Size([32]), torch.int64, min=0, max=8\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class CIFAR10(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(label).long()\n",
    "        return image, label\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(0.3),\n",
    "    transforms.RandomVerticalFlip(0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(x_train, y_train, transform=transform_train)\n",
    "test_dataset = CIFAR10(x_test, y_test, transform=transform_test)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "print(f\">> x: {x.shape}, {x.dtype}, min={x.min()}, max={x.max()}\")\n",
    "print(f\">> y: {y.shape}, {y.dtype}, min={y.min()}, max={y.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = ConvBlock(3, 32)\n",
    "        self.conv_block2 = ConvBlock(32, 64)\n",
    "        self.conv_block3 = ConvBlock(64, 128)\n",
    "        self.fc = nn.Linear(128 * 4 * 4, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def accuracy(y_pred, y):\n",
    "    y_pred = y_pred.argmax(dim=1)   # int64 (long)\n",
    "    return torch.eq(y_pred, y).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "## Hyperparameters\n",
    "set_seed(42)\n",
    "n_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "step_size = 1\n",
    "\n",
    "## Modeling\n",
    "model = Encoder(latent_dim=10).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()     # with logits\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/10] loss: 1.340 acc: 0.523 | val_loss: 1.166 val_acc: 0.598                                                    \n",
      "[  2/10] loss: 1.022 acc: 0.642 | val_loss: 0.935 val_acc: 0.676                                                    \n",
      "[  3/10] loss: 0.896 acc: 0.685 | val_loss: 0.830 val_acc: 0.708                                                    \n",
      "[  4/10] loss: 0.824 acc: 0.713 | val_loss: 0.796 val_acc: 0.723                                                    \n",
      "[  5/10] loss: 0.772 acc: 0.734 | val_loss: 0.709 val_acc: 0.758                                                    \n",
      "[  6/10] loss: 0.721 acc: 0.749 | val_loss: 0.746 val_acc: 0.746                                                    \n",
      "[  7/10] loss: 0.687 acc: 0.763 | val_loss: 0.681 val_acc: 0.771                                                    \n",
      "[  8/10] loss: 0.654 acc: 0.773 | val_loss: 0.697 val_acc: 0.762                                                    \n",
      "[  9/10] loss: 0.632 acc: 0.781 | val_loss: 0.709 val_acc: 0.752                                                    \n",
      "[ 10/10] loss: 0.603 acc: 0.792 | val_loss: 0.672 val_acc: 0.774                                                    \n"
     ]
    }
   ],
   "source": [
    "## Training loop\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    cur_epoch = f\"[{epoch:3d}/{n_epochs}]\"\n",
    "\n",
    "    ## Training\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    with tqdm(train_loader, leave=False, file=sys.stdout, dynamic_ncols=True, ascii=True) as pbar:\n",
    "        for i, (x, y) in enumerate(pbar):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            acc = accuracy(y_pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_acc += acc.item()\n",
    "\n",
    "            desc = f\"loss: {train_loss/(i + 1):.3f} acc: {train_acc/(i + 1):.3f}\"\n",
    "            pbar.set_description(cur_epoch + \" \" + desc)\n",
    "\n",
    "    ## Validation\n",
    "    model.eval()\n",
    "    valid_loss, valid_acc = 0, 0\n",
    "    with tqdm(test_loader, leave=False, file=sys.stdout, dynamic_ncols=True, ascii=True) as pbar:\n",
    "        for i, (x, y) in enumerate(pbar):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "\n",
    "            valid_loss += loss_fn(y_pred, y).item()\n",
    "            valid_acc += accuracy(y_pred, y).item()\n",
    "\n",
    "            val_desc = f\"val_loss: {valid_loss/(i + 1):.3f} val_acc: {valid_acc/(i + 1):.3f}\"\n",
    "            pbar.set_description(cur_epoch + \" \" + desc + \" | \" + val_desc)\n",
    "\n",
    "    if epoch % step_size == 0:\n",
    "        print(cur_epoch + \" \" + desc + \" | \" + val_desc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
